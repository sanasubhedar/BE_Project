{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Import libraries \nimport librosa\nimport librosa.display\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom matplotlib.pyplot import specgram\nimport pandas as pd\nimport glob \nfrom sklearn.metrics import confusion_matrix\nimport IPython.display as ipd  # To play sound in the notebook\nimport os\nimport sys\nimport warnings\n# ignore warnings \nif not sys.warnoptions:\n    warnings.simplefilter(\"ignore\")\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning) ","metadata":{"execution":{"iopub.status.busy":"2021-12-29T15:45:43.852709Z","iopub.execute_input":"2021-12-29T15:45:43.853072Z","iopub.status.idle":"2021-12-29T15:45:51.171794Z","shell.execute_reply.started":"2021-12-29T15:45:43.852979Z","shell.execute_reply":"2021-12-29T15:45:51.171028Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"TESS = \"/kaggle/input/toronto-emotional-speech-set-tess/tess toronto emotional speech set data/TESS Toronto emotional speech set data/\"\nRAV = \"/kaggle/input/ravdess-emotional-speech-audio/audio_speech_actors_01-24/\"\nSAVEE = \"/kaggle/input/surrey-audiovisual-expressed-emotion-savee/ALL/\"\nCREMA = \"/kaggle/input/cremad/AudioWAV/\"","metadata":{"execution":{"iopub.status.busy":"2021-12-29T15:45:51.173831Z","iopub.execute_input":"2021-12-29T15:45:51.174376Z","iopub.status.idle":"2021-12-29T15:45:51.179519Z","shell.execute_reply.started":"2021-12-29T15:45:51.174331Z","shell.execute_reply":"2021-12-29T15:45:51.178693Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Get the data location for SAVEE\ndir_list = os.listdir(SAVEE)\n\n# parse the filename to get the emotions\nemotion=[]\npath = []\nfor i in dir_list:\n    if i[-8:-6]=='_a':\n        emotion.append('male_angry')\n    elif i[-8:-6]=='_d':\n        emotion.append('male_disgust')\n    elif i[-8:-6]=='_f':\n        emotion.append('male_fear')\n    elif i[-8:-6]=='_h':\n        emotion.append('male_happy')\n    elif i[-8:-6]=='_n':\n        emotion.append('male_neutral')\n    elif i[-8:-6]=='sa':\n        emotion.append('male_sad')\n    elif i[-8:-6]=='su':\n        emotion.append('male_surprise')\n    else:\n        emotion.append('male_error') \n    path.append(SAVEE + i)\n    \n# Now check out the label count distribution \nSAVEE_df = pd.DataFrame(emotion, columns = ['labels'])\nSAVEE_df['source'] = 'SAVEE'\nSAVEE_df = pd.concat([SAVEE_df, pd.DataFrame(path, columns = ['path'])], axis = 1)\nSAVEE_df.labels.value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-12-29T15:45:51.180591Z","iopub.execute_input":"2021-12-29T15:45:51.180908Z","iopub.status.idle":"2021-12-29T15:45:51.532507Z","shell.execute_reply.started":"2021-12-29T15:45:51.180880Z","shell.execute_reply":"2021-12-29T15:45:51.531615Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# use the well known Librosa library for this task \nfname = SAVEE + 'DC_f11.wav'  \ndata, sampling_rate = librosa.load(fname)\nplt.figure(figsize=(15, 5))\nlibrosa.display.waveplot(data, sr=sampling_rate)\n\n# Lets play the audio \nipd.Audio(fname)\n","metadata":{"execution":{"iopub.status.busy":"2021-12-29T15:45:51.534382Z","iopub.execute_input":"2021-12-29T15:45:51.534804Z","iopub.status.idle":"2021-12-29T15:45:52.935179Z","shell.execute_reply.started":"2021-12-29T15:45:51.534770Z","shell.execute_reply":"2021-12-29T15:45:52.934510Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Lets play a happy track\nfname = SAVEE + 'DC_h11.wav'  \ndata, sampling_rate = librosa.load(fname)\nplt.figure(figsize=(15, 5))\nlibrosa.display.waveplot(data, sr=sampling_rate)\n\n# Lets play the audio \nipd.Audio(fname)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T15:45:52.936334Z","iopub.execute_input":"2021-12-29T15:45:52.936664Z","iopub.status.idle":"2021-12-29T15:45:53.511110Z","shell.execute_reply.started":"2021-12-29T15:45:52.936636Z","shell.execute_reply":"2021-12-29T15:45:53.510259Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"#  2. RAVDESS dataset","metadata":{}},{"cell_type":"code","source":"dir_list = os.listdir(RAV)\ndir_list.sort()\n\nemotion = []\ngender = []\npath = []\nfor i in dir_list:\n    fname = os.listdir(RAV + i)\n    for f in fname:\n        part = f.split('.')[0].split('-')\n        emotion.append(int(part[2]))\n        temp = int(part[6])\n        if temp%2 == 0:\n            temp = \"female\"\n        else:\n            temp = \"male\"\n        gender.append(temp)\n        path.append(RAV + i + '/' + f)\n\n        \nRAV_df = pd.DataFrame(emotion)\nRAV_df = RAV_df.replace({1:'neutral', 2:'neutral', 3:'happy', 4:'sad', 5:'angry', 6:'fear', 7:'disgust', 8:'surprise'})\nRAV_df = pd.concat([pd.DataFrame(gender),RAV_df],axis=1)\nRAV_df.columns = ['gender','emotion']\nRAV_df['labels'] =RAV_df.gender + '_' + RAV_df.emotion\nRAV_df['source'] = 'RAVDESS'  \nRAV_df = pd.concat([RAV_df,pd.DataFrame(path, columns = ['path'])],axis=1)\nRAV_df = RAV_df.drop(['gender', 'emotion'], axis=1)\nRAV_df.labels.value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-12-29T15:45:53.512334Z","iopub.execute_input":"2021-12-29T15:45:53.512643Z","iopub.status.idle":"2021-12-29T15:45:54.010392Z","shell.execute_reply.started":"2021-12-29T15:45:53.512611Z","shell.execute_reply":"2021-12-29T15:45:54.009460Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Pick a fearful track\nfname = RAV + 'Actor_14/03-01-06-02-02-02-14.wav'  \ndata, sampling_rate = librosa.load(fname)\nplt.figure(figsize=(15, 5))\nlibrosa.display.waveplot(data, sr=sampling_rate)\n\n# Lets play the audio \nipd.Audio(fname)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T15:45:54.011651Z","iopub.execute_input":"2021-12-29T15:45:54.011861Z","iopub.status.idle":"2021-12-29T15:45:54.428069Z","shell.execute_reply.started":"2021-12-29T15:45:54.011834Z","shell.execute_reply":"2021-12-29T15:45:54.427116Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Pick a happy track\nfname = RAV + 'Actor_14/03-01-03-02-02-02-14.wav'  \ndata, sampling_rate = librosa.load(fname)\nplt.figure(figsize=(15, 5))\nlibrosa.display.waveplot(data, sr=sampling_rate)\n\n# Lets play the audio \nipd.Audio(fname)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T15:45:54.430099Z","iopub.execute_input":"2021-12-29T15:45:54.430378Z","iopub.status.idle":"2021-12-29T15:45:54.884019Z","shell.execute_reply.started":"2021-12-29T15:45:54.430337Z","shell.execute_reply":"2021-12-29T15:45:54.883203Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# 3. TESS dataset\n","metadata":{}},{"cell_type":"code","source":"dir_list = os.listdir(TESS)\ndir_list.sort()\ndir_list","metadata":{"execution":{"iopub.status.busy":"2021-12-29T15:45:54.885167Z","iopub.execute_input":"2021-12-29T15:45:54.885402Z","iopub.status.idle":"2021-12-29T15:45:54.899921Z","shell.execute_reply.started":"2021-12-29T15:45:54.885375Z","shell.execute_reply":"2021-12-29T15:45:54.899011Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"path = []\nemotion = []\n\nfor i in dir_list:\n    fname = os.listdir(TESS + i)\n    for f in fname:\n        if i == 'OAF_angry' or i == 'YAF_angry':\n            emotion.append('female_angry')\n        elif i == 'OAF_disgust' or i == 'YAF_disgust':\n            emotion.append('female_disgust')\n        elif i == 'OAF_Fear' or i == 'YAF_fear':\n            emotion.append('female_fear')\n        elif i == 'OAF_happy' or i == 'YAF_happy':\n            emotion.append('female_happy')\n        elif i == 'OAF_neutral' or i == 'YAF_neutral':\n            emotion.append('female_neutral')                                \n        elif i == 'OAF_Pleasant_surprise' or i == 'YAF_pleasant_surprised':\n            emotion.append('female_surprise')               \n        elif i == 'OAF_Sad' or i == 'YAF_sad':\n            emotion.append('female_sad')\n        else:\n            emotion.append('Unknown')\n        path.append(TESS + i + \"/\" + f)\n\nTESS_df = pd.DataFrame(emotion, columns = ['labels'])\nTESS_df['source'] = 'TESS'\nTESS_df = pd.concat([TESS_df,pd.DataFrame(path, columns = ['path'])],axis=1)\nTESS_df.labels.value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-12-29T15:45:54.902317Z","iopub.execute_input":"2021-12-29T15:45:54.902559Z","iopub.status.idle":"2021-12-29T15:45:55.726788Z","shell.execute_reply.started":"2021-12-29T15:45:54.902529Z","shell.execute_reply":"2021-12-29T15:45:55.725945Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# lets play a fearful track \nfname = TESS + 'YAF_fear/YAF_dog_fear.wav' \n\ndata, sampling_rate = librosa.load(fname)\nplt.figure(figsize=(15, 5))\nlibrosa.display.waveplot(data, sr=sampling_rate)\n\n# Lets play the audio \nipd.Audio(fname)\n","metadata":{"execution":{"iopub.status.busy":"2021-12-29T15:45:55.728087Z","iopub.execute_input":"2021-12-29T15:45:55.728968Z","iopub.status.idle":"2021-12-29T15:45:56.240263Z","shell.execute_reply.started":"2021-12-29T15:45:55.728920Z","shell.execute_reply":"2021-12-29T15:45:56.239301Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# lets play a happy track \nfname =  TESS + 'YAF_happy/YAF_dog_happy.wav' \n\ndata, sampling_rate = librosa.load(fname)\nplt.figure(figsize=(15, 5))\nlibrosa.display.waveplot(data, sr=sampling_rate)\n\n# Lets play the audio \nipd.Audio(fname)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T15:45:56.242049Z","iopub.execute_input":"2021-12-29T15:45:56.242413Z","iopub.status.idle":"2021-12-29T15:45:56.768549Z","shell.execute_reply.started":"2021-12-29T15:45:56.242359Z","shell.execute_reply":"2021-12-29T15:45:56.767609Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# 4. CREMA-D dataset","metadata":{}},{"cell_type":"code","source":"dir_list = os.listdir(CREMA)\ndir_list.sort()\nprint(dir_list[0:10])","metadata":{"execution":{"iopub.status.busy":"2021-12-29T15:45:56.769904Z","iopub.execute_input":"2021-12-29T15:45:56.770139Z","iopub.status.idle":"2021-12-29T15:45:57.248707Z","shell.execute_reply.started":"2021-12-29T15:45:56.770111Z","shell.execute_reply":"2021-12-29T15:45:57.247780Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"gender = []\nemotion = []\npath = []\nfemale = [1002,1003,1004,1006,1007,1008,1009,1010,1012,1013,1018,1020,1021,1024,1025,1028,1029,1030,1037,1043,1046,1047,1049,\n          1052,1053,1054,1055,1056,1058,1060,1061,1063,1072,1073,1074,1075,1076,1078,1079,1082,1084,1089,1091]\n\nfor i in dir_list: \n    part = i.split('_')\n    if int(part[0]) in female:\n        temp = 'female'\n    else:\n        temp = 'male'\n    gender.append(temp)\n    if part[2] == 'SAD' and temp == 'male':\n        emotion.append('male_sad')\n    elif part[2] == 'ANG' and temp == 'male':\n        emotion.append('male_angry')\n    elif part[2] == 'DIS' and temp == 'male':\n        emotion.append('male_disgust')\n    elif part[2] == 'FEA' and temp == 'male':\n        emotion.append('male_fear')\n    elif part[2] == 'HAP' and temp == 'male':\n        emotion.append('male_happy')\n    elif part[2] == 'NEU' and temp == 'male':\n        emotion.append('male_neutral')\n    elif part[2] == 'SAD' and temp == 'female':\n        emotion.append('female_sad')\n    elif part[2] == 'ANG' and temp == 'female':\n        emotion.append('female_angry')\n    elif part[2] == 'DIS' and temp == 'female':\n        emotion.append('female_disgust')\n    elif part[2] == 'FEA' and temp == 'female':\n        emotion.append('female_fear')\n    elif part[2] == 'HAP' and temp == 'female':\n        emotion.append('female_happy')\n    elif part[2] == 'NEU' and temp == 'female':\n        emotion.append('female_neutral')\n    else:\n        emotion.append('Unknown')\n    path.append(CREMA + i)\n    \nCREMA_df = pd.DataFrame(emotion, columns = ['labels'])\nCREMA_df['source'] = 'CREMA'\nCREMA_df = pd.concat([CREMA_df,pd.DataFrame(path, columns = ['path'])],axis=1)\nCREMA_df.labels.value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-12-29T15:45:57.250346Z","iopub.execute_input":"2021-12-29T15:45:57.250584Z","iopub.status.idle":"2021-12-29T15:45:57.298165Z","shell.execute_reply.started":"2021-12-29T15:45:57.250555Z","shell.execute_reply":"2021-12-29T15:45:57.297209Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# A fearful track\nfname = CREMA + '1012_IEO_FEA_HI.wav'  \ndata, sampling_rate = librosa.load(fname)\nplt.figure(figsize=(15, 5))\nlibrosa.display.waveplot(data, sr=sampling_rate)\n\n# Lets play the audio \nipd.Audio(fname)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T15:45:57.299445Z","iopub.execute_input":"2021-12-29T15:45:57.299662Z","iopub.status.idle":"2021-12-29T15:45:57.636598Z","shell.execute_reply.started":"2021-12-29T15:45:57.299635Z","shell.execute_reply":"2021-12-29T15:45:57.635543Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# use the well known Librosa library for this task \nfname = CREMA + '1012_IEO_HAP_HI.wav'  \ndata, sampling_rate = librosa.load(fname)\nplt.figure(figsize=(15, 5))\nlibrosa.display.waveplot(data, sr=sampling_rate)\n\n# Lets play the audio \nipd.Audio(fname)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T15:45:57.638134Z","iopub.execute_input":"2021-12-29T15:45:57.638405Z","iopub.status.idle":"2021-12-29T15:45:57.937838Z","shell.execute_reply.started":"2021-12-29T15:45:57.638375Z","shell.execute_reply":"2021-12-29T15:45:57.936991Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# A fearful track\nfname = CREMA + '1012_IEO_FEA_HI.wav'  \ndata, sampling_rate = librosa.load(fname)\nplt.figure(figsize=(15, 5))\nlibrosa.display.waveplot(data, sr=sampling_rate)\n\n# Lets play the audio \nipd.Audio(fname)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T15:45:57.939330Z","iopub.execute_input":"2021-12-29T15:45:57.940108Z","iopub.status.idle":"2021-12-29T15:45:58.235442Z","shell.execute_reply.started":"2021-12-29T15:45:57.940061Z","shell.execute_reply":"2021-12-29T15:45:58.234845Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"df = pd.concat([SAVEE_df, RAV_df, TESS_df, CREMA_df], axis = 0)\nprint(df.labels.value_counts())\ndf.head()\ndf.to_csv(\"Data_path.csv\",index=False)","metadata":{"execution":{"iopub.status.busy":"2021-12-29T15:45:58.236367Z","iopub.execute_input":"2021-12-29T15:45:58.237300Z","iopub.status.idle":"2021-12-29T15:45:58.327156Z","shell.execute_reply.started":"2021-12-29T15:45:58.237246Z","shell.execute_reply":"2021-12-29T15:45:58.326035Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}}]}